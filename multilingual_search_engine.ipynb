{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "\n",
    "# NLP Libraries\n",
    "from flair.embeddings import BertEmbeddings, DocumentPoolEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data must be downloaded from Kaggle competition: <br>\n",
    "https://www.kaggle.com/c/quora-question-pairs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Encoder\n",
    "class TFEncoder(metaclass=ABCMeta):\n",
    "    def __init__(self, model_path:str):\n",
    "        self.model = hub.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal sentence encoder\n",
    "class USE(TFEncoder):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__(model_path)\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return self.model(text).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal sentence encoder trained on Question Answer pairs\n",
    "class USEQA(TFEncoder):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__(model_path)\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return self.model.signatures['question_encoder'](tf.constant(s))['outputs'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT models\n",
    "class BERT():\n",
    "    def __init__(self, model_name, layers=\"-2\", pooling_operation=\"mean\"):\n",
    "        self.embeddings = BertEmbeddings(model_name, layers=layers, pooling_operation=pooling_operation)\n",
    "        self.document_embeddings = DocumentPoolEmbeddings([self.embeddings], fine_tune_mode='nonlinear')\n",
    "        \n",
    "    def encode(self, text):\n",
    "        sentence = Sentence(text)\n",
    "        self.document_embeddings.embed(sentence)\n",
    "        return sentence.embedding.detach().numpy().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /var/folders/0s/skg4xy3d4_z6br1c9rlxqpg00000gn/T/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3'.\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3: 90.03MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3: 190.03MB\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3: 290.03MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3, Total size: 334.32MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3'.\n"
     ]
    }
   ],
   "source": [
    "# model_path = 'https://tfhub.dev/google/universal-sentence-encoder-qa/3'\n",
    "# model_path = '../../models/universal-sentence-encoder-qa3/'\n",
    "\n",
    "# https://arxiv.org/pdf/1803.11175.pdf\n",
    "# model_path = '../../models/universal-sentence-encoder-large5/' #best for english\n",
    "\n",
    "model_path = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\"\n",
    "# model_path = '../../models/universal-sentence-encoder-multilingual-large3/'\n",
    "\n",
    "# encoder = BERT('bert-base-uncased')\n",
    "encoder = USE(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode(['hello']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = encoder.encode(['hello']).shape[-1]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faiss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISS:\n",
    "    def __init__(self, dimensions:int):\n",
    "        self.dimensions = dimensions\n",
    "        self.index = faiss.IndexFlatL2(dimensions)\n",
    "        self.vectors = {}\n",
    "        self.counter = 0\n",
    "    \n",
    "    def add(self, text:str, v:list):\n",
    "        self.index.add(v)\n",
    "        self.vectors[self.counter] = (text, v)\n",
    "        self.counter += 1\n",
    "        \n",
    "    def search(self, v:list, k:int=10):\n",
    "        distance, item_index = self.index.search(v, k)\n",
    "        for dist, i in zip(distance[0], item_index[0]):\n",
    "            if i == -1:\n",
    "                break\n",
    "            else:\n",
    "                print(f'{self.vectors[i][0]}, %.2f'%dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Search Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word,  distance\n",
      "hello, 0.07\n",
      "bye, 0.83\n"
     ]
    }
   ],
   "source": [
    "index = FAISS(d)\n",
    "\n",
    "# index word\n",
    "t1 = 'hello'\n",
    "v1 = encoder.encode([t1])\n",
    "index.add(t1, v1)\n",
    "\n",
    "# index word\n",
    "t1 = 'bye'\n",
    "v1 = encoder.encode([t1])\n",
    "index.add(t1, v1)\n",
    "\n",
    "# search similar word\n",
    "t1 = 'hi'\n",
    "v1 = encoder.encode([t1])\n",
    "\n",
    "print('word,  distance')\n",
    "index.search(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4043"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a smaller amount of the dataset\n",
    "reduce_data = data.sample(frac=0.01, random_state=1)\n",
    "\n",
    "subset_to_ask = reduce_data.question1.values\n",
    "len(subset_to_ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Embeddings and Index all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4043/4043 [03:57<00:00, 17.01it/s]\n"
     ]
    }
   ],
   "source": [
    "index = FAISS(d)\n",
    "\n",
    "for q in tqdm(subset_to_ask):\n",
    "    emb = encoder.encode([q])\n",
    "    index.add(q, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(s, k=10):\n",
    "    emb = encoder.encode([s])\n",
    "    index.search(emb, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "Which are the must watch movies?, 0.59\n",
      "What are best Hollywood movies?, 0.61\n",
      "What are the best Hollywood movies ever?, 0.63\n",
      "What are some of the movies of Hollywood that you must watch?, 0.64\n",
      "List of best Hollywood movies 2016?, 0.66\n",
      "What movie can you watch all the time and never get tired of watching?, 0.67\n",
      "Which is the best movie ever?, 0.69\n",
      "Which are best Hollywood classic movies of all time?, 0.70\n",
      "What are your top 3 movie genres?, 0.74\n",
      "What are the 10 greatest horror movies of all time?, 0.75\n"
     ]
    }
   ],
   "source": [
    "print('English')\n",
    "search('What are your 10/10 movies?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish\n",
      "What are the best Hollywood movies ever?, 0.63\n",
      "What are best Hollywood movies?, 0.63\n",
      "Which are the must watch movies?, 0.65\n",
      "What are some of the movies of Hollywood that you must watch?, 0.65\n",
      "List of best Hollywood movies 2016?, 0.69\n",
      "Which is the best movie ever?, 0.70\n",
      "Which are best Hollywood classic movies of all time?, 0.70\n",
      "What movie can you watch all the time and never get tired of watching?, 0.70\n",
      "What are your top 3 movie genres?, 0.75\n",
      "What is the greatest movie ever?, 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Spanish')\n",
    "search('¿Cuáles son tus películas 10/10?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German\n",
      "What movie can you watch all the time and never get tired of watching?, 0.66\n",
      "What are best Hollywood movies?, 0.66\n",
      "What are the best Hollywood movies ever?, 0.66\n",
      "What are some of the movies of Hollywood that you must watch?, 0.67\n",
      "Which is the best movie ever?, 0.69\n",
      "Which are the must watch movies?, 0.71\n",
      "Which are best Hollywood classic movies of all time?, 0.73\n",
      "List of best Hollywood movies 2016?, 0.75\n",
      "What are your top 3 movie genres?, 0.75\n",
      "What is the greatest movie ever?, 0.75\n"
     ]
    }
   ],
   "source": [
    "print('German')\n",
    "search('Was sind deine 10/10 Filme?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian\n",
      "Which are the must watch movies?, 0.69\n",
      "What are best Hollywood movies?, 0.70\n",
      "List of best Hollywood movies 2016?, 0.71\n",
      "What are the best Hollywood movies ever?, 0.73\n",
      "What are some of the movies of Hollywood that you must watch?, 0.77\n",
      "Which are best Hollywood classic movies of all time?, 0.77\n",
      "What are your top 3 movie genres?, 0.77\n",
      "What are the 10 greatest horror movies of all time?, 0.80\n",
      "What movie can you watch all the time and never get tired of watching?, 0.82\n",
      "Which is the best movie ever?, 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Russian')\n",
    "search('Какие у тебя фильмы 10/10?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese\n",
      "What movie can you watch all the time and never get tired of watching?, 0.64\n",
      "Which is the best movie ever?, 0.71\n",
      "What are some of the movies of Hollywood that you must watch?, 0.72\n",
      "What is the greatest movie ever?, 0.73\n",
      "What are the best Hollywood movies ever?, 0.74\n",
      "What are best Hollywood movies?, 0.75\n",
      "Which are the must watch movies?, 0.81\n",
      "Which are best Hollywood classic movies of all time?, 0.82\n",
      "What are your top 3 movie genres?, 0.86\n",
      "What is the best comedy movie ever?, 0.87\n"
     ]
    }
   ],
   "source": [
    "print('Chinese')\n",
    "search('你的10/10电影是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese\n",
      "Which is the best movie ever?, 0.60\n",
      "What movie can you watch all the time and never get tired of watching?, 0.61\n",
      "What is the greatest movie ever?, 0.64\n",
      "What are some of the movies of Hollywood that you must watch?, 0.66\n",
      "What are the best Hollywood movies ever?, 0.67\n",
      "What are best Hollywood movies?, 0.69\n",
      "Which are the must watch movies?, 0.74\n",
      "Which are best Hollywood classic movies of all time?, 0.74\n",
      "What are the 10 greatest horror movies of all time?, 0.81\n",
      "List of best Hollywood movies 2016?, 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Japanese')\n",
    "search('あなたの10/10の映画は何ですか？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
